{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23e889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fde7e5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 775 entries, 0 to 774\n",
      "Data columns (total 21 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Team    775 non-null    object \n",
      " 1   Rnd     775 non-null    int64  \n",
      " 2   R       775 non-null    float64\n",
      " 3   ACS     775 non-null    float64\n",
      " 4   K:D     775 non-null    float64\n",
      " 5   KAST    775 non-null    float64\n",
      " 6   ADR     775 non-null    float64\n",
      " 7   KPR     775 non-null    float64\n",
      " 8   APR     775 non-null    float64\n",
      " 9   FKPR    775 non-null    float64\n",
      " 10  FDPR    775 non-null    float64\n",
      " 11  HS%     775 non-null    float64\n",
      " 12  CL%     775 non-null    float64\n",
      " 13  CW      775 non-null    float64\n",
      " 14  CP      775 non-null    float64\n",
      " 15  KMax    775 non-null    int64  \n",
      " 16  K       775 non-null    int64  \n",
      " 17  D       775 non-null    int64  \n",
      " 18  A       775 non-null    int64  \n",
      " 19  FK      775 non-null    int64  \n",
      " 20  FD      775 non-null    int64  \n",
      "dtypes: float64(13), int64(7), object(1)\n",
      "memory usage: 127.3+ KB\n",
      "count    775.000000\n",
      "mean       0.987279\n",
      "std        0.094472\n",
      "min        0.610000\n",
      "25%        0.950000\n",
      "50%        0.987279\n",
      "75%        1.030000\n",
      "max        1.350000\n",
      "Name: R, dtype: float64\n",
      "R\n",
      "0.987279    231\n",
      "1.080000     24\n",
      "1.010000     22\n",
      "1.020000     21\n",
      "0.960000     21\n",
      "1.070000     21\n",
      "1.000000     20\n",
      "0.890000     20\n",
      "0.970000     18\n",
      "0.950000     18\n",
      "1.050000     18\n",
      "1.040000     18\n",
      "1.030000     17\n",
      "0.980000     16\n",
      "0.920000     16\n",
      "1.060000     14\n",
      "0.900000     14\n",
      "0.930000     13\n",
      "0.940000     13\n",
      "0.880000     12\n",
      "0.990000     12\n",
      "1.100000     12\n",
      "0.910000     12\n",
      "1.150000     11\n",
      "1.120000     11\n",
      "0.840000     10\n",
      "0.870000     10\n",
      "1.160000     10\n",
      "0.820000      9\n",
      "0.850000      8\n",
      "1.090000      8\n",
      "1.140000      8\n",
      "0.860000      8\n",
      "1.130000      7\n",
      "1.170000      7\n",
      "0.800000      6\n",
      "1.180000      5\n",
      "0.790000      5\n",
      "1.110000      5\n",
      "0.830000      4\n",
      "0.750000      4\n",
      "1.190000      4\n",
      "1.220000      3\n",
      "0.780000      3\n",
      "0.810000      3\n",
      "0.770000      3\n",
      "0.740000      3\n",
      "1.210000      2\n",
      "1.200000      2\n",
      "0.760000      2\n",
      "0.710000      2\n",
      "0.730000      2\n",
      "1.250000      1\n",
      "0.660000      1\n",
      "0.720000      1\n",
      "1.350000      1\n",
      "0.700000      1\n",
      "0.610000      1\n",
      "1.270000      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#1. Data Collection\n",
    "# Load the dataset\n",
    "data = pd.read_csv('VCT_2024.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "columns = ['Region', 'Player', 'Team Abbreviated', 'Event', 'CL']\n",
    "data = data.drop(columns=columns)\n",
    "nanColumns = ['R', 'KAST', 'ADR', 'FKPR', 'FDPR', 'HS%', 'CL%', 'CW', 'CP']\n",
    "for nan in nanColumns:\n",
    "    data[[nan]] = data[[nan]].fillna(data[nan].mean())\n",
    "\n",
    "data.head()\n",
    "\n",
    "data.info()\n",
    "print(data['R'].describe())\n",
    "print(data['R'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaad1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Data Preprocessing\n",
    "# Normalize selected numeric columns\n",
    "num_cols = ['ACS', 'K:D', 'KAST', 'ADR', 'KPR', 'APR', 'FKPR', 'FDPR', 'HS%', 'CL%', 'CW', 'CP']\n",
    "scaler = MinMaxScaler()\n",
    "data[num_cols] = scaler.fit_transform(data[num_cols])\n",
    "\n",
    "# Encoding categorical columns\n",
    "data = pd.get_dummies(data, columns=['Team'], drop_first=True)\n",
    "\n",
    "# Choose target variable - assuming 'R' is the target for prediction\n",
    "target_column = 'R'  # Adjust this if you have a specific target for winning\n",
    "X = data.drop(columns=[target_column])\n",
    "y = data[target_column]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "abdd0c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Train/Test Split\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "64df9b78",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#4. Model Training and Evaluation\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Initialize SVM model\u001b[39;00m\n\u001b[32m      3\u001b[39m svm_model = SVC(kernel=\u001b[33m'\u001b[39m\u001b[33mlinear\u001b[39m\u001b[33m'\u001b[39m, C=\u001b[32m1\u001b[39m, probability=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43msvm_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Initialize Random Forest Classifier\u001b[39;00m\n\u001b[32m      7\u001b[39m rf_model = RandomForestClassifier(random_state=\u001b[32m42\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/svm/_base.py:207\u001b[39m, in \u001b[36mBaseLibSVM.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    197\u001b[39m     X, y = validate_data(\n\u001b[32m    198\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    199\u001b[39m         X,\n\u001b[32m   (...)\u001b[39m\u001b[32m    204\u001b[39m         accept_large_sparse=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    205\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m y = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    209\u001b[39m sample_weight = np.asarray(\n\u001b[32m    210\u001b[39m     [] \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight, dtype=np.float64\n\u001b[32m    211\u001b[39m )\n\u001b[32m    212\u001b[39m solver_type = LIBSVM_IMPL.index(\u001b[38;5;28mself\u001b[39m._impl)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/svm/_base.py:747\u001b[39m, in \u001b[36mBaseSVC._validate_targets\u001b[39m\u001b[34m(self, y)\u001b[39m\n\u001b[32m    745\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_validate_targets\u001b[39m(\u001b[38;5;28mself\u001b[39m, y):\n\u001b[32m    746\u001b[39m     y_ = column_or_1d(y, warn=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m747\u001b[39m     \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    748\u001b[39m     \u001b[38;5;28mcls\u001b[39m, y = np.unique(y_, return_inverse=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    749\u001b[39m     \u001b[38;5;28mself\u001b[39m.class_weight_ = compute_class_weight(\u001b[38;5;28mself\u001b[39m.class_weight, classes=\u001b[38;5;28mcls\u001b[39m, y=y_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/utils/multiclass.py:222\u001b[39m, in \u001b[36mcheck_classification_targets\u001b[39m\u001b[34m(y)\u001b[39m\n\u001b[32m    214\u001b[39m y_type = type_of_target(y, input_name=\u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[32m    216\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    217\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmulticlass\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    220\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmultilabel-sequences\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    221\u001b[39m ]:\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    223\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown label type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Maybe you are trying to fit a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    224\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mclassifier, which expects discrete classes on a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    225\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mregression target with continuous values.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values."
     ]
    }
   ],
   "source": [
    "#4. Model Training and Evaluation\n",
    "# Initialize SVM model\n",
    "svm_model = SVC(kernel='linear', C=1, probability=True)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Initialize Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Hyperparameter tuning for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30]\n",
    "}\n",
    "grid_search = GridSearchCV(rf_model, param_grid, cv=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best parameters for Random Forest:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0bb68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Model Evaluation\n",
    "# Predict using SVM\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Predict using Random Forest\n",
    "y_pred_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics for SVM\n",
    "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "svm_precision = precision_score(y_test, y_pred_svm, average='weighted', zero_division=0)\n",
    "svm_recall = recall_score(y_test, y_pred_svm, average='weighted')\n",
    "svm_f1 = f1_score(y_test, y_pred_svm, average='weighted')\n",
    "\n",
    "# Calculate metrics for Random Forest\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "rf_precision = precision_score(y_test, y_pred_rf, average='weighted', zero_division=0)\n",
    "rf_recall = recall_score(y_test, y_pred_rf, average='weighted')\n",
    "rf_f1 = f1_score(y_test, y_pred_rf, average='weighted')\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'SVM': [svm_accuracy, svm_precision, svm_recall, svm_f1],\n",
    "    'Random Forest': [rf_accuracy, rf_precision, rf_recall, rf_f1]\n",
    "})\n",
    "\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f681f797",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Visualization of Results\n",
    "# Plotting performance comparison\n",
    "results_df.set_index('Metric').plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.ylabel('Score')\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
